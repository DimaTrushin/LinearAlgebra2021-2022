\ProvidesFile{lecture26.tex}[Лекция 26]


\subsection{Алгоритм диагонализации на основе метода Якоби}
\label{subsection::JacobyAlg}

\begin{definition}
Пусть $B, L, U\in\operatorname{M}_n(F)$ -- матрицы такие, что $L$ нижнетреугольная с единицами на диагонали, $U$ верхнетреугольная.
Тогда представление $B = LU$ называется LU-разложением матрицы $B$.
\end{definition}

Отметим, что LU-разложение не всегда существует.
Можно показать, что для невырожденной матрицы $B$ оно существует тогда и только тогда, когда все угловые подматрицы $B_k$ невырождены.
Мы же показали этот результат только для симметрических матриц.%
\footnote{На самом деле можно рассмотреть несимметрическую форму $\beta\colon F^n\times F^n \to F$, считая левое $F^n$ и правое $F^n$ разными пространствами одной размерности.
Тогда приведенные в предыдущем разделе рассуждения остаются верны и в этом случае и доказывают LU-разложение в общем случае.
Другой подход -- сделать все на матричном языке.}
Важно, что LU-разложение обязательно единственно для невырожденной матрицы.

\begin{claim}
Пусть $B\in \operatorname{M}_n(F)$ -- некоторая невырожденная матрица.
\begin{enumerate}
\item Пусть $B = L_1 U_1 = L_2 U_2$ -- два LU-разложения матрицы $B$, тогда $L_1 = L_2$ и $U_1 = U_2$.

\item Если матрица $B$ -- симметрична и найдутся матрицы $C_1,C_2, D_1,D_2\in\operatorname{M}_n(F)$ такие, что $C_1, C_2$ -- верхнетреугольные с единицей на диагонали, $D_1, D_2$ -- диагональные и $B = C_1^t D_1 C_1 = C_2^t D_2 C_2$, то $C_1 = C_2$ и $D_1 = D_2$.
\end{enumerate}
\end{claim}
\begin{proof}
(1) Пусть $L_1 U_1 = L_2 U_2$, тогда $L_2^{-1}L_1 = U_2 U_1^{-1}$ (в силу обратимости).
Тогда левая часть -- нижне треугольная с единицами на диагонали, а правая часть -- верхне треугольная.
Такое может быть лишь когда они обе единичные, то есть $L_2^{-1} L_1 = E$ и $U_2 U_1^{-1} = E$, что и требовалось.

(2) Так как $C_1^t(DC_1)$ и $C_2^t(D_2 C_2)$ -- два LU-разложения, то $C_1 = C_2$ и $D_1C_1 = D_2C_2$.
Откуда получаем требуемое из обратимости $C_1 = C_2$.
\end{proof}

\subsubsection*{Алгоритм диагонализации на основе метода Якоби}

\paragraph{Дано}

Симметрическая матрица $B\in \operatorname{M}_n(F)$.

\paragraph{Задача}

Проверить, что все ее угловые подматрицы $B_k$ невырождены и если это так, то найти их значения, а также найти верхнетреугольную матрицу с единицами на диагонали $C\in \operatorname{M}_n(F)$ и диагональную матрицу $D\in\operatorname{M}_n(F)$ такие, что $B = C^t D C$.

\paragraph{Алгоритм}

\begin{enumerate}
\item Начнем приводить матрицу $B$ к верхнетреугольному виду элементарными преобразованиями первого типа, когда нам разрешено прибавлять строку с коэффициентом только к более низкой строке.
Возможны два исхода:
\begin{itemize}
\item На каком-то этапе получили, что на диагонали на $k$-ом месте стоит $0$, а под диагональю есть ненулевой элемент.
Это значит, что $\Delta_k = 0$.
Условие на матрицу не выполнено.

\item Мы привели матрицу $B$ к верхнетреугольной матрице $U$.
Переходим к следующему шагу.
\end{itemize}

\item Восстановим все необходимые данные по матрице $U$ следующим образом:
\begin{enumerate}
\item $D$ -- диагональ матрицы $U$.

\item $C =  D^{-1}U$.

\item $\Delta_k$ -- произведение первых $k$ элементов диагонали матрицы $D$.
\end{enumerate}
\end{enumerate}

\paragraph{Замечание}

Заметим, что данный метод работает с вдвое меньшим количеством операций нежели общий симметрический Гаусс.
Однако, для него требуется дополнительное условие, чтобы все  угловые подматрицы были невырожденные.
На практике же, для невырожденной матрицы, условие вырожденности минора -- это условие случающееся с нулевой вероятностью и в реальных данных скорее всего будет выполнено.
Но если даже оно не выполнено для невырожденной матрицы $B$, то можно взять случайную матрицу $C$ и рассмотреть $C^tBC$ вместо $B$.
Тогда с вероятностью единица, у новой матрицы все угловые миноры будут невырожденные.
Есть и другой способ.
Можно очень хитро модифицировать алгоритм выше, добавив один дополнительный шаг, который будет бороться с вырожденными угловыми минорами и станет работать всегда.


\subsection{Квадратичные формы}


\begin{definition}
Пусть $\beta\colon V\times V\to F$ -- некоторая билинейная форма (не обязательно симметричная), тогда отображение $Q\colon V\to F$ по правилу $Q(v) = \beta(v, v)$ называется квадратичной формой.
Если надо подчеркнуть связь с $\beta$ пишут $Q_\beta$.
 Множество квадратичных форм на пространстве $V$ будем обозначать через $\Quad(V)$.
\end{definition}

Отметим, что квадратичные формы являются векторным пространством над полем $F$.
Действительно, мы умеем складывать многочлены и умножать их на скаляры из $F$.

\paragraph{Однородность степени $2$}

Квадратичная форма является однородной функцией степени $2$ в следующем смысле.
Для любого $\lambda\in F$ и любого вектора $v\in V$ выполнено $Q(\lambda v) = \lambda^2 Q(v)$.


\paragraph{Замечание}

Идея квадратичной формы в следующем.
Когда нам задана билинейная форма, то мы имеем функцию двух аргументов, но она по каждому аргументу линейная.
В случае квадратичной формы, мы имеем функцию одного аргумента, однако, теряем линейность и становимся квадратичными по аргументу.
Забегая вперед, скажу, что окажется, что симметричные билинейные формы будут однозначно описываться квадратичными формами.
А так как для нас симметричные билинейные формы -- это самый интересный случай, то удобно иметь подобный механизм, когда в зависимости от задачи нам удобнее иметь два аргумента, но линейных или наоборот один, но квадратичный.


\paragraph{Квадратичные формы в координатах}

Если нам дана какая-то билинейная форма $\beta \colon F^n\times F^n\to F$ вида $\beta(x, y) = x^t B y$, где $B\in \operatorname{M}_n(F)$.
Квадратичная форма $Q_\beta\colon F^n\to F$ тогда имеет вид $Q(x) = x^t B x$.
Если расписать явно последнее выражение, то мы получим
\[
Q(x) = \beta(x,x) = x^t B x = \sum_{ij} b_{ij}x_ix_j = \sum_{i}b_{ii}x_i^2+ \sum_{i<j}(b_{ij} + b_{ji})x_i x_j
\]
Обратите внимание, что в отличие от билинейной формы, квадратичная форма не однозначно задается матрицей $B$.
Действительно, 
\[
Q(x_1,x_2) = 
\begin{pmatrix}
{x_1}&{x_2}
\end{pmatrix}
\begin{pmatrix}
{0}&{2}\\
{0}&{0}
\end{pmatrix}
\begin{pmatrix}
{x_1}\\{x_2}
\end{pmatrix}=
\begin{pmatrix}
{x_1}&{x_2}
\end{pmatrix}
\begin{pmatrix}
{0}&{0}\\
{2}&{0}
\end{pmatrix}
\begin{pmatrix}
{x_1}\\{x_2}
\end{pmatrix}=
\begin{pmatrix}
{x_1}&{x_2}
\end{pmatrix}
\begin{pmatrix}
{0}&{1}\\
{1}&{0}
\end{pmatrix}
\begin{pmatrix}
{x_1}\\{x_2}
\end{pmatrix}
=2x_1x_2
\]
За счет этого эффекта, при переходе к квадратичным формам от билинейных, мы теряем часть информации.
Однако, квадратичная форма однозначно задается симметрической матрицей $B$, то есть матрицей $B$ с условием $B^t = B$.
В примере выше -- это последний случай.

% Убрать, если сделаю вставку про тензоры
На самом деле есть беcкоординатный способ работать с квадратичными и билинейными формами, но я о нем рассказывать не буду.
Эта скользкая дорожка приведет нас напрямую к тензорам.
Пусть мы их и знаем, но сейчас я промолчу, как партизан.


\subsection{Связь между квадратичными и билинейными формами}


\begin{claim}
[Поляризационная формула]
Пусть $V$ -- векторное пространство над полем $F$, причем $2 \neq 0$, и $Q\colon V\to F$ -- квадратичная форма.
Тогда отображение $\beta_Q\colon V\times V\to F$ по правилу 
\[
(v,u)\mapsto \beta_Q(v, u) = \frac{1}{2}\left(Q(v+u) - Q(v) - Q(u)\right)
\]
является симметричной билинейной формой.
\end{claim}
\begin{proof}
Для начала заметим, что $\beta_Q$ по формуле выше действительно получается симметричной функцией, потому нам лишь надо показать, что она будет билинейной.
Для этого вспомним, что $Q(v) = \beta(v, v)$ для некоторой необязательно симметричной билинейной формы $\beta\colon V\times V\to F$.
Теперь подставим это выражение в определение $\beta_Q$ и получим
\begin{gather*}
\beta_Q(v, u) = \frac{1}{2}\left(\beta(v + u, v + u) - \beta(v, v) - \beta(u, u)\right) =\\
= \frac{1}{2}\left(\beta(v,v) + \beta(v, u) + \beta(u, v) + \beta(u,u)- \beta(v, v) - \beta(u, u)\right) = \frac{1}{2}\left(\beta(v, u) + \beta(u, v) \right)
\end{gather*}
% Последнее было симметризацией
Что и требовалось.
\end{proof}

\paragraph{Замечания}

\begin{itemize}
\item Таким образом у нас получается отображение $\Phi\colon\Quad(V) \to \Bil(V)$ по правилу $Q\mapsto \beta_Q$.
Кроме того, это отображение является линейным.

\item После выбора базиса билинейные и квадратичные формы задаются матрицами.
Тогда отображение записывается так: пусть квадратичная форма $Q(x) = x^t A x$ задается какой-нибудь матрицей $A$, тогда $\beta_Q(x, y) = x^t \left(\frac{A + A^t}{2}\right) y$.
Причем результат не зависит от выбора матрицы $A$, которой задается квадратичная форма (просто потому что поляризационная формула не зависит от этого выбора, а матричная формула -- это координатная запись поляризационной формулы).
\end{itemize}


Теперь сформулируем общее утверждение о взаимосвязи между билинейными и квадратичными формами.

\begin{claim}
\label{claim::SBilQuad}
Пусть $V$ -- векторное пространство над полем $F$, в котором $2 \neq 0$.
Пусть $\Psi\colon \Bil(V) \to \Quad(V)$ по правилу $\beta\mapsto Q_\beta$ и $\Phi\colon \Quad(V)\to \Bil(V)$ по правилу $Q \mapsto \beta_Q$ по поляризационной формуле.
Тогда
\begin{enumerate}
\item $\Psi\circ \Phi$ является тождественным на $\Quad(V)$.

\item $\Phi\circ \Psi$ является проектором на пространство симметричных билинейных форм вдоль подпространства кососимметричных билинейных форм.
\end{enumerate}

Как следствие:
\begin{enumerate}[\rm I.]
\item $\ker \Psi$ совпадает с подпространством кососимметричных билинейных форм.

\item $\Im \Psi$ совпадает с пространством всех квадратичных форм, то есть $\Psi$ сюръективно.

\item $\Psi$ и $\Phi$ являются взаимно обратными изоморфизмами между $\SBil(V)$ (симметричными билинейными формами) и $\Quad(V)$.
\end{enumerate}
\end{claim}
\begin{proof}
1) Проверяется в лоб прямым вычислением.
Пусть $Q(v) = \beta(v,v)$ -- некоторая квадратичная форма, тогда $\beta_Q(v,u) = \frac{1}{2}(\beta(v,u) + \beta(u,v))$ (как мы видели в доказательстве поляризационной формулы).
И теперь надо взять $Q_{\beta_Q}(v) =  \frac{1}{2}(\beta(v,v) + \beta(v,v)) = \beta(v,v)$.

2) Пусть $\SBil(V)$ -- пространство симметричных билинейных форм и $\ABil(V)$ -- пространство кососимметричных билинейных форм.
Тогда $\Bil(V) = \SBil(V) \oplus \ABil(V)$ по утверждению~\ref{claim::BilDirectSA}.
Нам надо показать, что $\Phi\circ \Psi$ зануляет кососимметричные билинейные формы и оставляет на месте все симметричные.
Но $\Psi$ отправляет форму $\beta(v, u)$ в форму $\beta(v,v)$.
Потому если форма кососимметрична, то результат ноль.
Теперь пусть $\beta$ -- симметричная форма.
Тогда она идет в $Q_\beta(v) = \beta(v,v)$, которая идет по поляризационной формуле в $\beta_{Q_\beta}(v, u)= \frac{1}{2}(\beta(v,u) + \beta(u,v)) = \beta(v,u)$.

I) По определению $\ABil(V) \subseteq \ker \Psi \subseteq \ker \Phi\circ \Psi = \ABil(V)$.

II) Для любой квадратичной формы $Q$ верно $Q = \Psi(\Phi(Q))$, значит $\Psi$ сюръективно.

III) Этот пункт непосредственно проверялся во время доказательства (1) и (2).

\end{proof}

\paragraph{Замечания}

\begin{itemize}
\item Таким образом нет разницы между симметрическими билинейными формами и квадратичными формами, в случае $2 \neq 0$ в поле $F$.
Это значит, что если вы что-то доказали для симметрической билинейной формы, то этот факт можно перевести на язык квадратичных форм и он там будет верен автоматически.
И наоборот, если вы что-то сделали для квадратичных форм, то вы автоматически что-то показали для билинейных.

\item Когда мы работаем с билинейными формами плохо то, что они имеют два аргумента.
Зато по каждому аргументу форма линейна.
Квадратичная форма имеет только один аргумент, зато она по нему не линейна, а является однородной функцией степени $2$.
В зависимости от задачи бывает удобнее пользоваться квадратичными формами, бывает билинейными.
Потому полезно понимать, что вы выигрываете, а что проигрываете при переходе от одних к другим.

\item Другой взгляд на последнее утверждение такой: квадратичные формы однозначно задаются симметрическими матрицами.

\end{itemize}


\subsection{Метод Лагранжа}

Когда нам задана симметрическая билинейная форма, одна из основных задач -- диагонализировать ее в каком-нибудь базисе.
Так как симметрические билинейные формы соответствуют квадратичным формам (утверждение~\ref{claim::SBilQuad}), то неплохо было бы понять, что это означает для последних.
Метод пристального взгляда говорит, что симметричная билинейная форма $\beta\colon F^n \times F^n \to F$ по правилу $(x, y)\mapsto x^t B y$ задана в диагональном виде тогда и только тогда, когда $Q_\beta(x) = a_{11}x_1^2 + \ldots + a_{nn}x_n^2$.
То есть на языке квадратичных форм диагонализация матрицы -- это представление формы в виде суммы квадратов координат с коэффициентами.
Существует универсальный метод, приводящий любую квадратичную форму к такому виду -- метод Лагранжа.%
\footnote{На мой взгляд метод Лагранжа не самый удачный.
Но тем не менее, для полноты картины я привожу здесь его подробное описание.}

Этот метод работает на языке замены координат.
Пусть у нас
\[
Q_\beta(x) = \sum_{ij}b_{ij}x_i x_j = b_{11}x_1^2 + \sum_{j=2}^n b_{1j}x_j x_1 + Q'(x_2,\ldots,x_n)
\]
Далее поведение метода зависит от того является ли коэффициент $b_{11}$ нулем.
Давайте в начале разберем типичный шаг метода, когда этот коэффициент не ноль.

В этом случае выделим полный квадрат из первых двух слагаемых
\[
Q_\beta(x) = b_{11}\left(x_1^2 + 2 \sum_{j=2}^n \frac{b_{1j}}{2 b_{11}}x_j x_1 + \left(\sum_{j=2}^n \frac{b_{1j}}{2 b_{11}}x_j \right)^2\right) - b_{11}\left(\sum_{j=2}^n \frac{b_{1j}}{2 b_{11}}x_j\right)^2 + Q'(x_2,\ldots,x_n)
\]
Тогда
\[
Q_\beta(x) = b_{11}\left(x_1 + \sum_{j=2}^n \frac{b_{1j}}{2 b_{11}}x_j \right)^2 + Q''(x_2,\ldots,x_n)
\]
Сделаем замену
\[
\left\{
\begin{aligned}
\bar x_1 &= x_1 + \sum_{j=2}^n \frac{b_{1j}}{2 b_{11}}x_j \\
\bar x_2 &= x_2\\
&\ldots\\
\bar x_n &= x_n
\end{aligned}
\right.
\quad\text{то есть}\quad
\begin{pmatrix}
{\bar x_1}\\{\bar x_2}\\{\vdots}\\{\bar x_n}
\end{pmatrix}
=
\begin{pmatrix}
{1}&{\frac{b_{12}}{2b_{11}}}&{\ldots}&{\frac{b_{1n}}{2b_{11}}}\\
{}&{1}&{}&{}\\
{}&{}&{1}&{}\\
{}&{}&{}&{1}\\
\end{pmatrix}
\begin{pmatrix}
{x_1}\\{x_2}\\{\vdots}\\{x_n}
\end{pmatrix}
\]
Теперь мы получили, что $Q(\bar x) = b_{11}\bar x_1^2 + Q''(\bar x_2,\ldots, \bar x_n)$.
Далее переходим к форме $Q''(\bar x_2,\ldots, \bar x_n)$ и повторяем процедуру.

Теперь давайте разберемся что делать, если $b_{11} = 0$.
Если хотя бы один из коэффициентов $b_{ii}\neq 0$, мы переставим координаты так, чтобы $x_i$ превратилась в $x_1$.
В противном случае $Q(x)$ вообще не зависит от $x_i^2$ ни для какого $i$.
Но тогда она должна зависеть от какого-то $x_i x_j$.
После переупорядочивания координат, мы можем считать, что это $x_1x_2$.
Тогда
\[
Q(x) = b_{12}x_1 x_2 + \sum_{\substack{i < j\\ (i, j)\neq (1, 2)}} b_{ij}x_i x_j
\]
В этом случае сделаем следующую замену переменных
\[
\left\{
\begin{aligned}
x_1 &= \bar x_1 + \bar x_2\\
x_2 &= \bar x_1 - \bar x_2\\
x_3 &= \bar x_3\\
&\vdots\\
x_n &= \bar x_n
\end{aligned}
\right.
\quad\text{то есть}\quad
\begin{pmatrix}
{x_1}\\{x_2}\\{x_3}\\{\vdots}\\{x_n}
\end{pmatrix}
=
\begin{pmatrix}
{1}&{1}&{}&{}&{}\\
{1}&{-1}&{}&{}&{}\\
{}&{}&{1}&{}&{}\\
{}&{}&{}&{\ddots}&{}\\
{}&{}&{}&{}&{1}\\
\end{pmatrix}
\begin{pmatrix}
{\bar x_1}\\{\bar x_2}\\{\bar x_3}\\{\vdots}\\{\bar x_n}
\end{pmatrix}
\]
Обратите внимание, что в этот раз мы выражаем старые переменные через новые, а не наоборот как в первом шаге.
После такой подстановки форма примет вид
\[
Q(\bar x) = b_{12}\bar x_1^2 - b_{12}\bar x_2^2 + Q'(\bar x_1,\ldots,\bar x_n)
\]
причем $Q'$ не зависит от $\bar x_1^2$ и $\bar x_2^2$.
После такой замены можно перейти к первому шагу.

\subsection{Классификация симметрических билинейных форм над алгебраически замкнутым полем}

\begin{claim}
Пусть $V$ -- векторное пространство над полем $F$, $F$ алгебраически замкнуто и $ 2 \neq 0$.
Тогда для любой симметрической билинейной формы $\beta\colon V\times V\to F$ существует базис, в котором ее матрица имеет вид
\[
\begin{pmatrix}
{E}&{0}\\
{0}&{0}
\end{pmatrix}
\]
причем размер блока $E$ совпадает с рангом $\beta$.
\end{claim}
\begin{proof}
При условии $2\neq 0$ в поле $F$ любая симметрическая билинейная форма диагонализируется по утверждению~\ref{claim::SBilToDiag}.
То есть $\beta(x,y) = a_{11}x_1 y_1 + \ldots + a_{kk}x_ky_k$, где $k\leqslant n$ (часть диагональных элементов может быть нулевыми).
Для каждого числа $a_{ii}$ найдем $s_i$ такой, что $s_i^2 = a_{ii}$.
Такое число найти можно в силу алгебраической замкнутости $F$, в нем решаются все уравнения вида $t^2 - a = 0$.
Теперь сделаем замену
\[
\bar x_1 = s_1 x_1,\ldots,\bar x_k = s_k x_k, \bar x_{k+1} = x_{k+1},\ldots,\bar x_n = x_n
\]
После такой замены $\beta(\bar x,\bar y) = x_1y_1 + \ldots x_k y_k$, что и требовалось.
\end{proof}

\paragraph{Замечания}

\begin{itemize}
\item Таким образом две симметрические матрицы $A,B\in \operatorname{M}_n(F)$ над алгебраически замкнутым полем $F$ задают одну и ту же билинейную форму в разных базисах тогда и только тогда, когда у них совпадают ранги.

\item Обратите внимание, что ранг -- это единственная содержательная характеристика симметрической билинейной формы над алгебраически замкнутым полем.
\end{itemize}

\section{Симметричные билинейные формы в вещественном пространстве}

\subsection{Классификация}

\begin{claim}
\label{claim::SBilReal}
Пусть $V$ -- векторное пространство над полем $\mathbb R$.
Тогда для любой симметрической билинейной формы $\beta\colon V\times V\to \mathbb R$ существует базис, в котором ее матрица имеет вид
\[
\begin{pmatrix}
{E}&{}&{}\\
{}&{-E}&{}\\
{}&{}&{0}\\
\end{pmatrix}
\]
причем количество единиц, минус единиц и нулей на диагонали не зависит от выбора базиса.
При этом количество единиц и минус единиц вместе совпадает с рангом $\beta$.
\end{claim}
\begin{proof}
В силу утверждения~\ref{claim::SBilToDiag}, мы можем привести форму к диагональному виду $\beta(x,y) = a_{11}x_1 y_1 + \ldots + a_{kk}x_ky_k$, где $k\leqslant n$ (часть диагональных элементов -- ноль).
При этом считаем, что сначала идут положительные $a_{ii}$, а потом отрицательные.
В отличие от алгебраически замкнутого случая, мы можем извлекать корни только из положительных чисел.
Потому сделаем такую замену
\[
\bar x_1 = \sqrt{|a_{11}|} x_1,\ldots,\bar x_k = \sqrt{|a_{kk}|} x_k, \bar x_{k+1} = x_{k+1},\ldots,\bar x_n = x_n
\]
Тогда форма примет вид 
\[
\beta(\bar x,\bar y) = \bar x_1\bar y_1+\ldots +\bar x_s \bar y_s - \bar x_{s+1}\bar y_{s+1} - \ldots - \bar x_k \bar y_k
\]

Теперь давайте докажем, что количество единиц, минус единиц и нулей не зависит от выбора базиса.
Количество нулей -- это размерность ядра формы, а количестве единиц и минус единиц -- это ранг формы.
Потому нам лишь надо доказать, что количество единиц и минус единиц не зависит от выбора базиса.

Предположим противное -- пусть зависит.
Пусть найдутся два базиса $e_1,\ldots,e_n$ и $f_1,\ldots,f_n$, так что форма в них имеет вид
\begin{align*}
\beta(x, y) &= x_1y_1+\ldots +x_s y_s - x_{s+1}y_{s+1} - \ldots - x_k y_k\\
\beta(\bar x,\bar  y) &= \bar x_1\bar y_1+\ldots +\bar x_t \bar y_t - \bar x_{t+1}\bar y_{t+1} - \ldots - \bar x_k \bar y_k\\
\end{align*}
Пусть для определенности $s > t$.
Тогда положим $W = \langle e_1,\ldots, e_s\rangle$ и $U = \langle f_{t+1},\ldots, f_n\rangle$.
Заметим, что $Q_\beta(w) > 0$ для любого ненулевого $w\in W$ и $Q_\beta(u) \leqslant 0$ для любого $u\in U$.
Следовательно подпространства $W$ и $U$ могут пересекаться только по нулю.
С другой $\dim W+\dim U = s + n - t > n$, а значит $\dim(W\cap U) > 0$, противоречие.
\end{proof}

\paragraph{Замечание}

Очень полезно о диагонализации симметричных форм думать в терминах квадратичных.
А именно, после диагонализации формы мы получили $Q_\beta(x) = a_{11}x_1^2 + \ldots +a_{kk}x_k^2$.
Теперь, чтобы сделать замену координат, нам надо внести под корень коэффициент $a_{ii}$.

\begin{definition}
Пусть $\beta\colon V\times V\to \mathbb R$ -- симметричная билинейная форма.
Тогда количество положительных, отрицательных и нулевых элементов в ее диагональной форме называются ее индексами инерции.
Это тоже самое, что посчитать количество единиц, минус единиц и нулей в диагональной форме из единиц, минус единиц и нулей.

Число единиц -- это положительный индекс инерции, он будет обозначаться $\#1$.
Число минус единиц -- это отрицательный индекс инерции, он будет обозначаться $\#-1$.
Число нулей будем для единообразия обозначать $\#0$.
\end{definition}

Обратите внимание, что утверждение~\ref{claim::SBilReal} показывает корректность этого определения, то есть, что указанные числа не зависят от диагональной формы, а зависят только от самой билинейной формы.



\subsection{Геометрический смысл Сигнатуры}

\begin{claim}
Пусть $V$ -- векторное пространство над $\mathbb R$ и $\beta\colon V\times V\to \mathbb R$ -- симметричная билинейная форма на $V$.
\begin{enumerate}
\item Пусть $W\subseteq V$ -- максимальное по вложению подпространство такое, что $\beta(w, w) > 0$ для любого ненулевого $w\in W$.
Тогда $\#1 = \dim W$.

\item Пусть $W\subseteq V$ -- максимальное по вложению подпространство такое, что $\beta(w, w) < 0$ для любого ненулевого $w\in W$.
Тогда $\#-1 = \dim W$.
\end{enumerate}
\end{claim}
\begin{proof}
Если заменить форму $\beta$ на $-\beta$, то количество единиц в сигнатуре $-\beta$ равно количеству минус единиц в сигнатуре $\beta$.
Потому достаточно доказать только первое утверждение.


Так как $\beta(w, w) > 0$ для любого ненулевого $w\in W$, то $\beta|_W$ не вырождена, а значит $V = W\oplus W^\bot$  по утверждению~\ref{claim::NonDegRestrictionBil} пункт~2.
Пусть $e_1,\ldots,e_k$ -- базис $W$, в котором $\beta|_W$ диагональная с единицами на диагонали.
Так же выберем $e_{k+1},\ldots,e_n$ базис $W^\bot$, в котором $\beta|_{W^\bot}$ диагонализуема с единицами, минус единицами и нулями на диагонали.
Если в сигнатуре $\beta|_{W^\bot}$ есть хотя бы одна единица, например на $k+1$ месте, то на подпространстве $W+\langle e_{k+1}\rangle$ в базисе $e_1,\ldots,e_{k+1}$ форма $\beta$ задана в виде $\beta(x, y) = x^t y$ и потому $\beta(x,x)$ положительна для любого ненулевого вектора, что противоречит выбору $W$.
Значит в сигнатуре $\beta|_{W^\bot}$ могут быть только $-1$ и $0$.
А значит в сигнатуре $\beta$ единицы взялись только из блока для $\beta|_W$, что завершает доказательство.


\end{proof}

\paragraph{Замечания}

\begin{itemize}
\item Стоит отметить, что аналог формулы из предыдущего утверждения не подходит для вычисления $\#0$.
Например, если взять $\beta\colon \mathbb R^2 \times \mathbb R^2 \to \mathbb R$ заданную матрицей $\left(\begin{smallmatrix}{0}&{1}\\{1}&{0}\end{smallmatrix}\right)$, то для $W = \langle e_1\rangle$ выполнено $\beta|_W = 0$.
Однако, форма $\beta$ невырождена, а значит $\#0 = 0$.
В этом случае $\#0$ надо искать как размерность ядра формы.

\item Аналогично можно показать следующее утверждение.
Если $\beta\colon V\times V\to \mathbb R$ -- симметричная билинейная форма, $U\subseteq V$ -- подпространство такое, что $\beta|_U$ невырождена, тогда $\# 1$ для $\beta$ не меньше, чем $\# 1$ для $\beta|_W$ и $\#-1$ для $\beta$ не меньше, чем $\#-1$ для $\beta|_W$.
\end{itemize}

\begin{claim}
Пусть $V$ -- векторное пространство над $\mathbb R$ и $\beta\colon V\times V\to \mathbb R$ -- симметричная билинейная форма на $V$.
Пусть $W\subseteq V$ -- максимальное по вложению подпространство такое, что $\beta|_W = 0$.
Тогда $\dim W = \min(\#1, \#-1) + \#0$.
\end{claim}
\begin{proof}
Обратите внимание, что $\ker \beta \subseteq W$.
Действительно, если это не  так, то на подпространстве $W+\ker \beta$ форма $\beta$ полностью нулевая, но это подпространство больше по включению.
Теперь выберем базис пространства $V$ следующим образом: в начале возьмем $e_1,\ldots,e_k \in \ker \beta$ -- базис ядра.
Потом дополним его до базиса $W$ векторами $e_{k+1},\ldots,e_{k+m}$.
Пусть $U = \langle e_{k+1},\ldots,e_{k+m}\rangle$.
Тогда $W = \ker \beta \oplus U$.
Так же дополним $W$ прямым слагаемым до всего подпространства $V$, то есть найдем такое $E\subseteq V$, что $V = W \oplus E$.

Заметим, что ограничение $\beta'\colon U\times E \to \mathbb R$ не имеет левого ядра.
Действительно, если у этой формы есть левое ядро, то эти векторы лежат в ядре $\beta$, которое не пересекается с $U$, противоречие.
Значит, мы можем найти в $E$ подпространство $U'$ такой же размерности, что и $U$ такие, что ограничение $\beta$ на $U\times U'$ будет невырожденной.
А значит, мы можем выбрать базис в $U$ и $U'$ так, что матрица в нем будет иметь вид
\[
\begin{pmatrix}
{\beta|_{U}}&{\beta|_{U\times U'}}\\
{\beta|_{U'\times U}}&{\beta|_{U'}}\\
\end{pmatrix}
=
\begin{pmatrix}
{0}&{E}\\
{E}&{*}
\end{pmatrix}
\]
Симметричным гауссом вычитая более верхние строки из более нижних и более левые столбцы из более правых, мы можем занулить блок справа внизу.
Значит можно так поменять базис, что
\[
\begin{pmatrix}
{\beta|_{U}}&{\beta|_{U\times \bar U}}\\
{\beta|_{\bar U\times U}}&{\beta|_{\bar U}}\\
\end{pmatrix}
=
\begin{pmatrix}
{0}&{E}\\
{E}&{0}
\end{pmatrix}
\]
для некоторого нового подпространства $\bar U$.

На подпространстве $U\oplus E$ форма $\beta$ не вырождена, а значит $U\oplus E = U \oplus \bar U \oplus(U \oplus \bar U)^\bot$ по утверждению~\ref{claim::NonDegRestrictionBil} пункт~(2).
В итоге мы выбрали базис в $U\oplus \bar U$ так, что матрица билинейной формы на этом подпространстве имеет вид
\[
\begin{pmatrix}
{0}&{E}\\
{E}&{0}
\end{pmatrix}
\]
А значит, выбрав базис в ортогональном дополнении и в ядре, мы получим, что матрица для $\beta$ имеет вид
\[
B_\beta = 
\begin{pmatrix}
{0}&{0}&{0}&{0}\\
{0}&{0}&{E}&{0}\\
{0}&{E}&{0}&{0}\\
{0}&{0}&{0}&{C}\\
\end{pmatrix}
\]
При этом $W$ порождено базисными векторами соответствующим первым двум блокам.

Теперь мы можем допривести полученную матрицу к диагональному виду.
В перестановкой базисных векторов можно сделать
\[
\begin{pmatrix}
{0}&{E}\\
{E}&{0}\\
\end{pmatrix}
\mapsto
\begin{pmatrix}
{0}&{1}&{}&{}&{}\\
{1}&{0}&{}&{}&{}\\
{}&{}&{0}&{1}&{}\\
{}&{}&{1}&{0}&{}\\
{}&{}&{}&{}&{\ddots}\\
\end{pmatrix}
\]
А теперь мы видим, что у каждого блока $2$ на $2$ сигнатура состоит из одной единицы и одной минус единицы.
Далее мы доприводим блок $C$ к диагональному виду.
Получаем
\[
B_\beta =
\begin{pmatrix}
{0}&{}&{}&{}&{}\\
{}&{E}&{}&{}&{}\\
{}&{}&{-E}&{}&{}\\
{}&{}&{}&{E}&{}\\
{}&{}&{}&{}&{-E}\\
\end{pmatrix}
\]
Здесь последние два блока взялись из матрицы $C$.
Откуда мы видим, что размерность $W$ не больше $\#0 + \min(\#1, \#-1)$.
Давайте покажем, что если размерность $W$ строго меньше, то мы можем его увеличить.
Если размерность строго меньше, то это значит, что в сигнатуре $C$ есть и единицы и минус единицы.
Вернемся к базису, в котором матрица билинейной формы имеет вид
\[
B_\beta = 
\begin{pmatrix}
{0}&{0}&{0}&{0}\\
{0}&{0}&{E}&{0}\\
{0}&{E}&{0}&{0}\\
{0}&{0}&{0}&{C}\\
\end{pmatrix}
\]
Пусть $U$ -- подпространство, на котором билинейная форма задана матрицей $C$.
Так как в сигнатуре $C$ есть и единицы и минус единицы, мы можем выбрать в $C$ два ортогональных вектора $f$ и $g$ такие, что $\beta(f,f) = 1$ и $\beta(g,g) = -1$.
Тогда можно проверить, что на подпространстве $W + \langle f + g\rangle$ форма $\beta$ будет тождественно нулем.
А это противоречит максимальности $W$.
Это противоречие возникло из предположения, что $\dim W < \#0 + \min(\#1, \#-1)$.
\end{proof}