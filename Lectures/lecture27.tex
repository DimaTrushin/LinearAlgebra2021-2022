\ProvidesFile{lecture27.tex}[Лекция 27]


\subsection{Положительная и отрицательная определенность формы над $\mathbb R$}

\begin{definition}
Пусть $\beta\colon V\times V\to \mathbb R$ -- симметричная билинейная форма.
Тогда
\begin{itemize}
\item $\beta$ (или $Q_\beta$) называется положительно определенной (или кратко положительной), если $Q_\beta(v) > 0$ для любого $v\neq 0$, $v\in V$.

\item $\beta$ (или $Q_\beta$) называется отрицательно определенной (или кратко отрицательной), если $Q_\beta(v) < 0$ для любого $v\neq 0$, $v\in V$.

\item $\beta$ (или $Q_\beta$) называется неотрицательно определенной (или кратко неотрицательной), если $Q_\beta(v) \geqslant 0$ для любого $v\in V$.

\item $\beta$ (или $Q_\beta$) называется неположительно определенной (или кратко неположительной), если $Q_\beta(v) \leqslant 0$ для любого $v\in V$.

\item В противном случае $\beta$ и $Q_\beta$ называются неопределенными.
\end{itemize}
\end{definition}

\paragraph{Замечание}

Обратите внимание, что определение зависит от значений квадратичной формы, а не самой билинейной формы.
То есть $\beta(u,v)$ может быть вообще говоря каким угодно (если $\beta(u, v) >0$, то $\beta(-u, v)< 0$), а мы смотрим на $\beta(v, v)$.

Ниже я все определения отразил в единой табличке.
В ней подразумевается, что билинейная форма задана на пространстве размерности $n$.
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
{\bf Термин}&{\bf Обозначения}&{\bf Условие}&{\bf Индексы}\\
\hline
{Положительная}&{$\beta>0$ или $Q>0$}&{$\forall x\neq 0\Rightarrow Q(x) > 0$}&{$\# 1 = n$}\\
\hline
{Отрицательная}&{$\beta<0$ или $Q<0$}&{$\forall x\neq 0\Rightarrow Q(x) < 0$}&{$\#-1 = n$}\\
\hline
{Неотрицательная}&{$\beta\geqslant0$ или $Q\geqslant0$}&{$\forall x\Rightarrow Q(x) \geqslant 0$}&{$\#-1 = 0$}\\
\hline
{Неположительная}&{$\beta\leqslant0$ или $Q\leqslant0$}&{$\forall x\Rightarrow Q(x) \leqslant 0$}&{$\#1 = 0$}\\
\hline
{Неопределенная}&{}&{$\exists x, y\Rightarrow Q(x) > 0$ и $Q(y)<0$}&{$\#1>0$ и $\#-1>0$}\\
\hline
\end{tabular}
\end{center}

\begin{claim}
[Критерий Сильвестра]
\label{claim::SilvCrit}
Пусть $\beta\colon V\times V\to \mathbb R$ -- симметрическая билинейная форма и пусть в некотором базисе $e_1,\ldots,e_n$ она записывается в виде $\beta(x, y) = x^t B y$, где $B\in \operatorname{M}_n(\mathbb R)$ -- симметрическая матрица.
Обозначим ее угловые миноры через $\Delta_1,\ldots,\Delta_n$.
Тогда
\begin{enumerate}
\item Форма $\beta$ положительно определена тогда и только тогда, когда $\Delta_i > 0$ для любого $i$.

\item Форма $\beta$ отрицательно определена тогда и только тогда, когда $\sgn \Delta_i = (-1)^i$.
\end{enumerate}
\end{claim}
\begin{proof}
(1) Пусть $W = \langle e_1,\ldots,e_i\rangle$.
Если $\beta$ положительно определена, то $\beta|_W$ тоже положительно определена.
Кроме того $\Delta_i = \det \beta|_W$.
Так как над полем $\mathbb R$ знак определителя формы не зависит от базиса (раздел~\ref{subsection::BilChar}), то достаточно посчитать этот определитель в удобном базисе.
Так как $\beta|_W$ положительно определена, то $\#1 = n$, то есть в каком то базисе она задана единичной матрицей.

Обратно, пусть $\Delta_i > 0$.
Тогда можно применить алгоритм Якоби.
Значит форма приводится к диагональному виду с числами $\Delta_1, \Delta_2/\Delta_1,\ldots,\Delta_n/\Delta_{n-1}$ на диагонали.
Значит $\#1 = n$, то есть форма положительно определена.

(2) Заметим, что $\beta$ отрицательно определена тогда и только тогда, когда $-\beta$ положительно определена.
Тогда $\sgn\Delta_i(-\beta) = (-1)^i\sgn\Delta_i(\beta)$.
Теперь утверждение следует из первого пункта.
\end{proof}

\subsection{Графики Квадратичных форм}

Пусть $V = \mathbb R^2$.
Тогда квадратичная форма $Q(x, y)$ задает функцию от двух переменных.
Давайте нарисуем ее графики в различных ситуациях.

\begin{enumerate}
\item Положительно определенная форма $z = x^2 + y^2$.
Начало координат -- точка минимума.

\includegraphics[scale = 0.5]{Figures/graph_positive.png}

\item Отрицательно определенная форма $z = - x^2 - y^2$.
Начало координат -- точка максимума.

\includegraphics[scale = 0.5]{Figures/graph_negative.png}

\item Неотрицательно определенная форма $z = x^2$.
Минимум достигается на прямой $ x = 0$.

\includegraphics[scale = 0.5]{Figures/graph_non_negative.png}

\item Неположительно определенная форма $z = - x^2$.
Максимум достигается на прямой $x = 0$.

\includegraphics[scale = 0.5]{Figures/graph_non_positive.png}

\item Неопределенная форма $z = x^2 - y^2$.
Начало координат -- седловая точка.

\includegraphics[scale = 0.5]{Figures/graph_saddle.png}
\end{enumerate}


\subsection{Анализ поверхности}

Квадратичные формы применяются для анализа поверхности графика функции от многих переменных.
Давайте я вкратце обрисую как.
Пусть $f\in C^2(\mathbb R^n)$ -- функция $n$ переменных, дифференцируемая дважды и вторые производные все непрерывны.
Тогда для любой точки $a\in \mathbb R^n$ выполнено разложение Тейлора
\[
f(z) = f(a) + \sum_{i=1}^n \frac{\partial f}{\partial x_i}(a)(z_i-a_i) + \sum_{ij=1}^n\frac{\partial^2 f}{\partial x_i\partial x_j}(a)(z_i-a_i)(z_j-a_j) + o(|z - a|^2)
\]
Здесь $o(|z-a|^2) = |z-a|^2 o(1)$, где $o(1)\to 0$ когда $z \to a$.
Геометрический смысл слагаемых следующий
\begin{enumerate}
\item Первое слагаемое $f(a)$ -- значение функции в точке.
Тут я никого этим не удивил.
Это лучшее приближение константой для нашей функции в точке $a$.

\item Второе слагаемое
\[
\sum_{i=1}^n \frac{\partial f}{\partial x_i}(a)(z_i-a_i)
\]
задает касательную плоскость в точке $a$ к графику функции $y = f(z)$.
То есть это линейное приближение для графика функции.
Эта плоскость горизонтальна тогда и только тогда, когда $ \frac{\partial f}{\partial x_i}(a) = 0$ для всех $1\leqslant i\leqslant n$.

\item Третье слагаемое 
\[
\sum_{ij=1}^n\frac{\partial^2 f}{\partial x_i\partial x_j}(a)(z_i-a_i)(z_j-a_j)
\]
является квадратичным приближением для графика функции.
Матрица с коэффициентами $\frac{\partial^2 f}{\partial x_i\partial x_j}(a)$ задает квадратичную форму называемую гессианом.
Если касательная плоскость горизонтальна, то сигнатура этой квадратичной формы определяет поведение графика в окрестности точки.
\begin{itemize}
\item Если форма положительно определена, то это точка локального минимума.

\item Если форма отрицательно определена, то это точка локального максимума.

\item Если форма не вырождена и неопределена, то это седловая точка
\end{itemize}
\end{enumerate}


\newpage
\section{Евклидовы пространства}

\subsection{Определение и примеры}

\begin{definition}
Евклидово пространство -- это пара $V$ и $({-},{-})$, где 
\begin{itemize}
\item $V$ -- векторное пространство над полем $\mathbb R$.

\item $({-},{-})\colon V\times V\to \mathbb R$ -- билинейная форма
\end{itemize}
При этом выполнены следующие аксиомы:
\begin{enumerate}
\item Форма $({-},{-})$ симметрическая.

\item Форма $({-},{-})$ положительно определена.
\end{enumerate}
Такая билинейная форма называется скалярным произведением.
\end{definition}

Очень часто, для краткости, когда задано евклидово пространство $V, ({-},{-})$, говорят, что $V$ является евклидовым пространством, подразумевая, что на нем есть скалярное произведение.

\paragraph{Примеры}

\begin{enumerate}
\item Пространство $\mathbb R^n$ со стандартным скалярным произведением $(x,y) = x^t y$.
Тогда $Q(x) = x^t x = \sum_{i=1}^n x_i^2 > 0$ при $x\neq 0$.

\item Пространство $\Matrix{n}$ со скалярным произведением $(A, B) = \tr(A^t B)$.
Тогда $Q(A) = \tr(A^t A) = \sum_{i,j=1}^n a_{ij}^2 > 0$ при $A\neq 0$.

\item Пусть $C[0,1]$ -- пространство непрерывных функций на отрезке $[0,1]$ сл скалярным произведением $(f,g) = \int_0^1 f(x) g(x)\,dx$.
Тогда $Q(f) = \int_0^1 f^2(x)\,dx > 0$ при $f \neq 0$.%
\footnote{В силу непрерывности, если $f(x)\neq 0$, то в какой-то окрестности $(x-\delta, x+\delta)$ точки $x$ имеем $|f(y)| > |f(x)| - \varepsilon$.}
\end{enumerate}

Важный вопрос: а как задавать скалярные произведения на некотором пространстве $V$?
Если в $V$ выбрать базис, то оно превратится в $\mathbb R^n$.
Тогда скалярное произведение задается симметричной матрицей $B$ с положительной сигнатурой.
Самый неудобный момент здесь заключается в том, что вообще говоря, глядя на матрицу $B$ не очевидно является ли она положительно определенной или нет.
Для этого надо пользоваться критерием Сильвестра (утверждение~\ref{claim::SilvCrit}).
Оказывается есть способ лучше, его мы обсудим далее.


\subsection{Ортогональные и ортонормированные базисы}

\begin{definition}
Пусть $V$ -- евклидово пространство.
Тогда
\begin{itemize}
\item Набор $v_1,\ldots,v_k\in V$ называется ортогональным, если $(v_i,v_j) = 0$ для всех $i\neq j$.


\item Набор $v_1,\ldots,v_k\in V$ называется ортонормированным, если он ортогонален и $(v_i,v_i) = 1$ для любого $i$.
\end{itemize}
Если $e_1,\ldots,e_n$ -- базис $V$, то он называется ортогональным или ортонормированным базисом, если набор $e_1,\ldots,e_n$ ортогонален или ортонормирован.
\end{definition}

\paragraph{Замечания}

\begin{itemize}
\item Базис является ортогональным тогда и только тогда, когда матрица скалярного произведения в нем диагональная.

\item Базис является ортонормированным тогда и только тогда, когда матрица скалярного произведения в нем единичная.

\item Утверждение~\ref{claim::SBilReal} говорит, что матрицу скалярного произведения всегда можно привести к единичной в некотором базисе.
То есть ортонормированные базисы существуют.

\item Процесс применяемый в методе Якоби (раздел~\ref{subsection::JacobyAlg}) превращает любой базис в ортогональный.%
\footnote{В евклидовых пространствах этот процесс называется процессом ортогонализации Грама-Шмидта.
Определение будет дальше.}
\end{itemize}


\begin{claim}
\label{claim::ScalarDef}
Пусть $V$ -- векторное пространство над $\mathbb R$.
Тогда для любого базиса $e_1,\ldots,e_n$ существует единственное скалярное произведение $({-},{-})$ на $V$ такое, что $e_1,\ldots,e_n$ является ортонормированным базисом.
\end{claim}
\begin{proof}
Зафиксируем базис $e_1,\ldots,e_n$.
Тогда задать билинейную форму -- это все равно, что задать матрицу $B\in \Matrix{n}$ (утверждение~\ref{claim::BilinearMatrices}).
Когда такая матрица $B$ задает скалярное произведение, в котором $e_1,\ldots,e_n$ -- ортонормированный базис?
Тогда и только тогда, когда $B = E$.
\end{proof}

По ортогональным и ортонормированным базисам удобно раскладывать произвольные векторы.

\begin{claim}
Пусть $V$ -- евклидово пространство, $e_1,\ldots,e_n$ -- базис и $v\in V$ -- произвольный вектор.
Тогда
\begin{enumerate}
\item Если $e_1,\ldots,e_n$ ортогональный, то 
\[
v = \frac{(v,e_1)}{(e_1,e_1)}e_1 + \ldots + \frac{(v,e_n)}{(e_n,e_n)} e_n
\]

\item Если $e_1,\ldots,e_n$ ортонормированный, то
\[
v = (v,e_1)e_1+\ldots+(v,e_n)e_n
\]
\end{enumerate}
\end{claim}
\begin{proof}
Вторая формула есть элементарное следствие первой, так как $(e_i,e_i) = 1$ для ортонормированного базиса.
Потому достаточно доказать первую формулу.
Пусть $v = \alpha_1e_1+\ldots+\alpha_n e_n$.
Умножим скалярно левую и правую часть на вектор $e_k$, тогда получим $(v, e_k) = \sum_{i=1}^n \alpha_i(e_i, e_k) = \alpha_k (e_k,e_k)$.
Значит, $\alpha_k = \frac{(v,e_k)}{(e_k,e_k)}$, что и требовалось.
\end{proof}


\begin{claim}
Пусть $A\in \Matrix{n}$.
Тогда следующие условия равносильны
\begin{enumerate}
\item $A^t A = E$.

\item $AA^t = E$.

\item $A^t = A^{-1}$.
\end{enumerate}
\end{claim}
\begin{proof}
Это следует из существования и единственности обратного при наличии левого или правого обратного (утверждение~\ref{claim::InvertibleDiscription}).
\end{proof}

\begin{definition}
Матрица $A\in \Matrix{n}$ называется ортогональной, если выполнено одно из эквивалентных свойств из предыдущего утверждения, например, $A^t A = E$.
\end{definition}

\paragraph{Замечание}

Рассмотрим в $\mathbb R^n$ стандартное скалярное произведение.
Если $A\in\Matrix{n}$, то условие $A^t A = E$ означает, что столбцы матрицы $A$ образуют ортонормированный базис.
Условие $A A^t = E$ означает, что строки матрицы $A$ образуют ортонормированный базис.
Важно понимать, что эти условия эквивалентны.
А именно, если вы возьмете ортонормированный базис в $\mathbb R^n$ и поставите эти векторы в столбцы матрицы $A$, то строки этой матрицы автоматически образуют некий другой ортонормированный базис в $\mathbb R^n$.

\begin{claim}
\label{claim::OrthoBasisDiscrEucl}
Пусть $V$ -- евклидово пространство.
Тогда
\begin{enumerate}
\item Если $e_1,\ldots,e_n$ и $f_1,\ldots,f_n$ -- два ортонормированных базиса, то матрица перехода между ними будет ортогональна.

\item Если $e_1,\ldots,e_n$ -- ортонормированный базис и $C\in \Matrix{n}$ -- ортогональная матрица, то базис $(e_1,\ldots,e_n)C$ будет ортонормированным.
\end{enumerate}
\end{claim}
\begin{proof}
(1) Пусть $(f_1,\ldots,f_n) = (e_1,\ldots,e_n)C$, где $C\in \Matrix{n}$.
Так оба базиса ортонормированные, то матрица скалярного произведения в каждом из этих базисов единичная.
По правилу изменения матрицы билинейной формы при смене базиса получаем $E = C^t E C$.
Значит $C$ ортогональная.

(2) Пусть $(f_1,\ldots,f_n) = (e_1,\ldots,e_n)C$.
В базисе $e_1,\ldots,e_n$ матрица билинейной формы $E$, так как он ортонормированный.
Матрица в базисе $f_1,\ldots,f_n$ будет $C^t E C$.
Так как $C$ ортогональная, то это будет $E$, то есть $f_1,\ldots,f_n$ -- ортонормированный базис.
\end{proof}

Таким образом за переход между ортонормированными базисами отвечают только ортогональные матрицы.

\subsection{Классификация Евклидовых пространств}

Если у нас есть два векторных пространства $V$ и $U$, то они изоморфны (то есть по сути одно и то же векторное пространство, но заданное по-разному) тогда и только тогда, когда у них одинаковые размерности (утверждение~\ref{claim::VectorClassific}).
Теперь мы хотим решить ту же самую задачу для евклидовых пространств -- понять, когда они будут одинаковыми.
Для начала надо объяснить, что значит изоморфизм евклидовых пространств.

\begin{definition}
Пусть $V$ и $U$ -- два евклидовых пространства.
Линейное отображение $\phi\colon V\to U$ называется изоморфизмом евклидовых пространств, если
\begin{enumerate}
\item $\phi$ -- изоморфизм векторных пространств.

\item Для любых $v,u\in V$ выполнено $(v, u) = (\phi(v), \phi(u))$.%
\footnote{Здесь слева скалярное произведение в пространстве $V$, а с права в пространстве $U$.}
\end{enumerate}
При наличии изоморфизма между евклидовыми пространствами $V$ и $U$ они называются изоморфными.
\end{definition}

Второе условие в определении можно выразить коммутативностью следующей диаграммы
\[
\xymatrix@R=6pt@C=40pt{
	{V\times V}\ar[dd]^{\phi\times \phi}\ar[rd]&{}&{(v,u)}\ar@{|->}[dd]\ar@{|->}[rd]&{}\\
	{}&{\mathbb R}&{}&{(v,u) = (\phi(v),\phi(u))}\\
	{U\times U}\ar[ru]&{}&{(\phi(v),\phi(u))}\ar@{|->}[ru]&{}
}
\]
Смысл определения в том, что при изоморфизме не только вектора и операции над ними переходят в соответствующие вектора и операции, но и скалярное произведение на первом пространстве превращается в скалярное произведение на втором после применения измоморфизма.
Значит при таком изоморфизме вся структура евклидова пространства сохраняется, а значит мы считаем, что такие пространства одинаковые, как евклидовы пространства.
Более того, все свойства таких пространств (если они выражены в терминах евклидова пространства) одинаковые и одно можно безболезненно менять на другое, если это удобно.


\begin{claim}
\label{claim::EuclideanIsom}
Два евклидовых пространства $V$ и $U$ изоморфны тогда и только тогда, когда $\dim V = \dim U$.
\end{claim}
\begin{proof}
Ясно, что у изоморфных пространств одинаковая размерность.
Потому надо показать, что из условия $\dim V = \dim U$ найдется изоморфизм, согласованный со скалярным произведением.
Давайте выберем ортонормированный базис $e_1,\ldots,e_n$ в $V$ и ортонормированный базис $f_1,\ldots,f_n$ в $U$.
Тогда построим линейное отображение $\phi\colon V\to U$ отправляющее $e_i\mapsto f_i$ (такое найдется единственное по утверждению~\ref{claim::LinMapExist}).
Если векторы $v,u\in V$ имеют координаты $x,y\in \mathbb R^n$ в базисе $e_1,\ldots,e_n$, то векторы $\phi(v),\phi(u)\in U$ имеют те же самые координаты $x,y$ в базисе $f_1,\ldots,f_n$.
Тогда $(v,u) = x^ty$ и $(\phi(v),\phi(u)) = x^ty$.
\end{proof}

\paragraph{Замечания}

\begin{itemize}
\item Таким образом добавление скалярного произведения к пространству не увеличивает количество не изоморфных векторных пространств.

\item Пространство $\mathbb R^2$ со стандартным скалярным произведением является <<школьной плоскостью>>, которую мы все долго и упорно изучали в курсе геометрии школьной программы.
А пространство $\mathbb R^3$ со стандартным произведением является <<школьным пространством>>.

\item Самым важным с идейной точки зрения является следующее наблюдение, которое вытекает из предыдущего утверждения.
Пусть мы хотим доказать что-то про два вектора $v,u\in V$ в каком-то евклидовом пространстве.
Тогда они обязательно содержатся в каком-то двумерном подпространстве $U\subseteq V$.
Само $U$ тоже является евклидовым вместе с ограничением скалярного произведения с $V$.
Но у нас есть школьная плоскость, которая тоже является двумерным евклидовым пространством.
А значит, это то же самое пространство, что и $U$.
То есть нам достаточно доказать факт для произвольных двух векторов на школьной плоскости.
Получается, что автоматически можно пользоваться результатами школьной геометрии.
Аналогичная идея работает с тремя векторами и сведением задачи к школьной стереометрии.

\item Несмотря на то, что можно пользоваться школьной геометрией, бывает полезно понять, как именно доказывать те или иные утверждения пользуясь формализмами линейной алгебры напрямую.
Потому я буду периодически демонстрировать какие-то вещи в лоб.
\end{itemize}


\subsection{Геометрия в Евклидовых пространствах}

\begin{definition}
Пусть $V$ -- евклидово пространство и $v\in V$ -- произвольный вектор.
Определим длину вектора $|v| = \sqrt{(v,v)}$.
\end{definition}

\paragraph{Замечания}

\begin{itemize}
\item Именно для того, чтобы определить длину произвольного вектора, нам нужна положительная определенность в определении скалярного произведения.

\item Обратите внимание, что $|v| = 0$ тогда и только тогда, когда $v = 0$.

\item Если выбрать ортонормированный базис, то $|x| = \sqrt{\sum_{i=1}^n x_i^2}$.
То есть это $|{-}|_2$ норма на $\mathbb R^n$.
На самом деле можно развивать теорию норм на произвольных векторных пространствах, как это делается в функциональном анализе.
\end{itemize}

\begin{claim}
[Неравенство Коши-Буняковского]
Пусть $V$ -- евклидово пространство, $v,u\in V$, тогда $|(v,u)|\leqslant |v| |u|$.
Кроме того, равенство достигается тогда и только тогда, когда $u$ и $v$ лежат на одной прямой.
\end{claim}
\begin{proof}
Так как у нас всего два вектора, можно считать, что $V$ двумерно.
Выберем первый базисный вектор $e_1$ вдоль $v$ (если $v$ нулевой, то выбираем любой), а второй -- любой ортогональный к $e_2$ и длины $1$.
Тогда
\[
v = 
\begin{pmatrix}
{a}\\{0}
\end{pmatrix}
\quad\text{и}\quad
u = 
\begin{pmatrix}
{b}\\{c}
\end{pmatrix}
\]
Тогда $|(v, u)| = |ab|$, а $|v||u| = |a|\sqrt{b^2 + c^2}$.
Доказываемое неравенство превращается в $|ab|\leqslant |a|\sqrt{b^2 + c^2}$, что очевидно.

Давайте проанализируем, когда в нем достигается равенство.
Во-первых, если $a = 0$.
В этом случае $v$ и $u$ лежат на одной прямой.
Если $a \neq 0$, то мы получаем условие $|b| = \sqrt{b^2 + c^2}$, что равносильно тому, что $c = 0$.
В этом случае векторы тоже лежат на одной прямой.
Обратно, если векторы лежат на одной прямой, то $v = \lambda e$ и $u = \mu e$ для некоторого ненулевого вектора $e\in V$.
Тогда $(v,u) = \lambda\mu (e,e)$, а с другой стороны $|v||u| = |\lambda e||\mu e| = |\lambda \mu| |e|^2 = |\lambda \mu|(e,e)$.
\end{proof}

\paragraph{Замечание} 

Хочу обратить внимание на то, что по сути доказательство можно было закончить на первой строчке, где я ссылаюсь  на школьную геометрию.
Вся остальная часть всего лишь доказывала факт из школьной геометрии.
Это было сделано для полноты изложения.
К тому же я продемонстрировал метод последовательного выбора удобных базисных векторов, который часто применяется при решении задач аналитической геометрии.
Подобный метод позволяет упростить разбор общего случая в координатах за счет наличия большого количества нулей в векторах.
В нашем случае ноль был всего один, но это сильно сократило вычисления.

Из неравенства Коши-Буняковского следует, что для любых двух ненулевых векторов $v,u\in V$ верно $-1\leqslant \frac{(v,u)}{|v| |u|}\leqslant 1$.
А значит найдется единственное число $\alpha\in [0,\pi]$ такое, что $\cos \alpha = \frac{(v,u)}{|v| |u|}$.

\begin{definition}
Пусть $V$ -- евклидово пространство и $v,u\in V$ -- два вектора.
Тогда число $\alpha$ такое, что $\cos \alpha = \frac{(v,u)}{|v| |u|}$, называется углом между векторами $v$ и $u$.
Будем этот угол обозначать через $\angle(v, u)$.
\end{definition}

\paragraph{Замечание}

Так как два вектора $v$ и $u$ всегда лежат внутри <<школьной плоскости>>, то определение угла превращается в то самое определение угла, которое дается в школьном курсе геометрии.
Потому от этого угла надо ожидать ровно то же самое поведение, к которому мы привыкли в курсе школьной геометрии.
Просто потому, что это тот же самый угол.


\begin{claim}
[Теорема Пифагора]
\label{claim::Pythagoras}
Пусть $V$ -- евклидово пространство и $v,u\in V$ -- два ортогональных вектора, тогда $|v + u|^2 = |v|^2 + |u|^2$.
\end{claim}
\begin{proof}
Формальное доказательство в этом случае является наиболее простым:
\[
|v+u|^2 = (v+u, v+u) = (v,v) + (v,u)+(u,v) +(u,u) = (v,v) + (u,u) = |v|^2 + |u|^2
\]
Здесь $(v,u)=(u,v) = 0$ из ортогональности $u$ и $v$.
\end{proof}

Процесс, применяемый к базисным векторам в методе Якоби (раздел~\ref{subsection::JacobyAlg}), в случае евклидова пространства называется ортогонализацией Грама-Шмидта.
Единственное отличие -- ортогонализация Грама-Шмидта применяется не только к линейно независимым векторам, а к произвольным системам векторов.

\subsubsection*{Ортогонализация методом Грама-Шмидта}

\paragraph{Дано}

Евклидово пространство $V$, система векторов $\{v_1,\ldots,v_k\}\subseteq V$.%
\footnote{Обратите внимание, что $V$ не обязательно задано как пространство столбцов $\Vector{n}$.
Это может быть и пространство многочленов определенной степени или пространство тригонометрических функций, или вообще что угодно.
Даже если $V$ задано как $\Vector{n}$, то скалярное произведение не обязательно стандартное, т.е. скалярное произведение может быть задано любой положительной симметрической матрицей.}

\paragraph{Задача}

Найти систему ортогональных векторов $\{u_1,\ldots,u_r\}\subseteq V$ такую, что $\langle v_1,\ldots,v_k\rangle = \langle u_1,\ldots,u_r\rangle$.

\paragraph{Алгоритм}

\begin{enumerate}
\item В качестве первого вектора $u_1$ берем первый ненулевой вектор из $v_i$.
Если таких нет, то ответ -- пустое множество.

\item Пусть мы нашли вектора $u_1,\ldots,u_s$ и пусть $v_d$ -- первый еще не просмотренный вектор среди $v_i$.
Посчитать вектор 
\[
u' = v_d - \frac{(v_d, u_1)}{(u_1,u_1)} u_1 - \ldots - \frac{(v_d, u_s)}{(u_s, u_s)}u_s
\]

\item Если $u' \neq 0$ положим $u_{s+1} = u'$, иначе пропустим $v_d$.
Теперь перейдем к предыдущему шагу с вектором $v_{d+1}$ вместо $v_d$.
\end{enumerate}

% Надо переместить вперед, ближе к объемам
\subsection{Матрица Грама}
\label{subsection::Gram}

Давайте поговорим о еще одном объекте, который возникает в связи с конечной системой векторов в Евклидовом пространстве.
Таким объектом является матрица Грама.
Она в частности используется для определения объемов.

\begin{definition}
Пусть $V$ -- евклидово пространство и $v_1,\ldots,v_k\in V$ -- произвольный набор векторов ($k$ НЕ обязательно равно размерности пространства).
Тогда матрица
\[
G(v_1,\ldots,v_k) =
\begin{pmatrix}
{(v_1,v_1)}&{\ldots}&{(v_1,v_k)}\\
{\vdots}&{\ddots}&{\vdots}\\
{(v_k,v_1)}&{\ldots}&{(v_k,v_k)}\\
\end{pmatrix}
\in\Matrix{k}
\]
называется матрицей Грама системы векторов $v_1,\ldots,v_k$.%
\footnote{Обратите внимание, тут важен порядок векторов.
То есть формально матрица Грама зависит от набора $(v_1,\ldots,v_k)\in V^k$.}
\end{definition}

Если $e_1,\ldots,e_n$ -- некоторый базис пространства $V$, то $B = G(e_1,\ldots,e_n)$ -- матрица скалярного произведения заданная в базисе $e_1,\ldots,e_n$.
Таким образом матрица Грама -- это некоторое обобщение матрицы билинейной формы.

Теперь вспомним, что у любой билинейной формы есть операторная запись.
Давайте введем следующее обозначение: для произвольных векторов $w, u\in V$ положим $w\cdot u = (w, u)$.
Тогда для набора $v = (v_1,\ldots,v_k)$ выполнено
\[
G(v_1,\ldots,v_k) = 
\begin{pmatrix}
{v_1}\\{\vdots}\\{v_k}
\end{pmatrix}
\cdot
\begin{pmatrix}
{v_1}&{\ldots}&{v_k}
\end{pmatrix}
=
v^t \cdot v
\]

Пусть теперь $C\in \MatrixDim{k}{r}$ -- некоторая матрица.
Тогда из набора $(v_1,\ldots,v_k)$ можно построить новый набор $(u_1,\ldots,u_r) = (v_1,\ldots,v_k)C$ или кратко $u = vC$.
Тогда 
\[
G(u) = G(vC) = (vC)^t \cdot vC = C^t v^t \cdot v C = C^t G(v) C
\]
То есть $G((v_1,\ldots,v_k)C) = C^t G(v_1,\ldots,v_k)C$.


\begin{claim}
\label{claim::GramMatrixFull}
Пусть $v_1,\ldots,v_k\in V$ -- произвольный набор векторов в евклидовом пространстве.
Тогда
\begin{enumerate}
\item Пусть $\alpha_1,\ldots,\alpha_k \in \mathbb R$, введем обозначение $\alpha = (\alpha_1,\ldots,\alpha_k)^t$.
Тогда следующие условия эквивалентны:
\begin{enumerate}
\item $\alpha_1 v_1 + \ldots + \alpha_k v_k = 0$.

\item $G(v_1,\ldots,v_k)\alpha= 0$.

\item $\alpha^tG(v_1,\ldots,v_k)\alpha= 0$.
\end{enumerate}
\item $\rk G(v_1,\ldots,v_k) = \dim \langle v_1,\ldots,v_k\rangle$.

\item  $\det G(v_1,\ldots,v_k)\geqslant 0$.
При этом равенство достигается тогда и только тогда, когда векторы линейно зависимы.

\item Если $C\in\Matrix{k}$ является матрицей элементарного преобразования I или II типа, то 
\[
\det G(v_1,\ldots,v_k) = \det G((v_1,\ldots,v_k)C)
\]
\end{enumerate}
\end{claim}
\begin{proof}
1) Пусть $v = (v_1,\ldots,v_k)$.
Тогда условие $v\alpha = 0$ влечет, что $v^t \cdot v\alpha = 0$.
Но это означает, что $G(v_1,\ldots,v_k) \alpha = 0$.
Домножая слева на $\alpha^t$ получаем, что $\alpha^t G(v_1,\ldots,v_k) \alpha = 0$.
Осталось показать из последнего в первое.
Для этого заметим, что $0 = \alpha^t G(v_1,\ldots,v_k) \alpha = \alpha^t v^t \cdot v\alpha = (v\alpha, v\alpha)$.
А значит $v\alpha = 0$.

2) Пункт~(1) эквивалентность (a) и (b) означает, что векторы $v_1,\ldots,v_k$ обладают теми же линейными зависимостями, что и столбцы матрицы $G(v_1,\ldots,v_k)$.
В частности столбцовый ранг $G(v_1,\ldots,v_k)$ равен рангу системы векторов $(v_1,\ldots,v_k)$.
А последняя совпадает с размерностью линейной оболочки $\langle v_1,\ldots,v_k\rangle$.

3) Давайте на пространстве $\mathbb R^k$ рассмотрим билинейную форму $\beta(x,y) = x^t G(v_1,\ldots,v_k)y$.
Давайте покажем, что она не отрицательно определена.
Тогда, ее определитель должен быть не отрицательным.
Действительно, тогда в каком-то базисе ее матрица диагональна с $1$ и $0$ на диагонали, а значит в этом базисе определитель будет неотрицательным.
Но определитель билинейной формы не меняет знак при замене базиса (раздел~\ref{subsection::BilChar}).
Теперь остается лишь проверить, что $\beta(x,x)\geqslant 0$ для любого $x\in \mathbb R^k$.
Действительно
\[
x^t G(v_1,\ldots,v_k) x = x^t v^t\cdot v x = (vx, vx) \geqslant 0
\]
Последнее неравенство выполнено для любого вектора $vx\in V$ по определению скалярного произведения.

4) Если $C$ -- матрица элементарного преобразования, то $G((v_1,\ldots,v_k)C) = C^t G(v_1,\ldots,v_k)C$.
А значит $\det(G((v_1,\ldots,v_k)C)) = \det(G(v_1,\ldots,v_k))\det C^2$.
Но для элементарных преобразований I и II типов $\det C = \pm 1$.
\end{proof}

Заметим, что из третьего пункта следует вот какое наблюдение.
Если $v_1,\ldots, v_k$ -- линейно независимый набор векторов, из которого процессом ортогонализации Грама-Шмидта мы получили набор $u_1,\ldots,u_k$, то $\det G(u_1,\ldots,u_k) = \det G(v_1,\ldots,v_k)$.
